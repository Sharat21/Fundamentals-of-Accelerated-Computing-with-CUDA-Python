# NVIDIA CUDA Python with Numba — Course Work

## Overview
This repository contains my completed coursework from **NVIDIA’s CUDA Python with Numba** training. The course focuses on accelerating Python applications using **Numba** to compile and launch **CUDA kernels** on NVIDIA GPUs.

## What This Covers
- GPU acceleration of NumPy operations using Numba
- Writing and launching custom CUDA kernels in Python
- Using CUDA’s thread hierarchy for parallel execution
- Managing GPU memory efficiently for performance

## Key Skills Learned
- GPU-accelerating NumPy ufuncs with minimal code changes  
- Configuring parallelism using CUDA grids and threads  
- Writing custom CUDA device kernels with Numba  
- Applying memory coalescing and shared memory to improve bandwidth  
- Using atomic operations to avoid race conditions  

## Course Sections Implemented
### 1. Introduction to CUDA Python with Numba
- Numba decorators for GPU acceleration  
- Optimizing host-to-device and device-to-host memory transfers  

### 2. Custom CUDA Kernels in Python
- CUDA parallel thread hierarchy  
- Launching massively parallel kernels  
- Atomic operations for safe parallel execution  

### 3. Multidimensional Grids & Shared Memory
- 2D grid and matrix operations  
- Shared memory usage for memory coalescing

- ## Outcome
Completion of this course demonstrates the ability to build and optimize **GPU-accelerated Python applications** using **Numba and CUDA** on NVIDIA GPUs.
